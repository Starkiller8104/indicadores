# -*- coding: utf-8 -*-
"""Untitled15.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iBZw-Hu_ReT1opeD1gPKDrwhTKEY8SXE
"""

import io, re, os, requests, pandas as pd, pytz, feedparser
from datetime import datetime
from urllib.parse import quote_plus
from bs4 import BeautifulSoup
from openpyxl import load_workbook
import streamlit as st

st.set_page_config(page_title="Automatizaci√≥n Indicadores", page_icon="üìä", layout="centered")

def _get_app_password() -> str:
    # 1) Streamlit secrets
    try:
        return st.secrets["APP_PASSWORD"]
    except Exception:
        pass
    # 2) Variable de entorno
    if os.getenv("APP_PASSWORD"):
        return os.getenv("APP_PASSWORD")
    # 3) Respaldo (¬°c√°mbiala!)
    return "Indicadores2025"

def _check_password() -> bool:
    if "auth_ok" not in st.session_state:
        st.session_state.auth_ok = False

    def _try_login():
        pw = st.session_state.get("password_input", "")
        st.session_state.auth_ok = (pw == _get_app_password())
        st.session_state.password_input = ""  

    if st.session_state.auth_ok:
        return True

    st.title("üîí Acceso restringido")
    st.text_input("Contrase√±a", type="password", key="password_input", on_change=_try_login, placeholder="Escribe tu contrase√±a‚Ä¶")
    if not st.session_state.auth_ok and st.session_state.get("password_input","") == "":
        st.caption("Introduce la contrase√±a para continuar.")
    elif not st.session_state.auth_ok:
        st.error("Contrase√±a incorrecta.")
    return False


if not _check_password():
    st.stop()

st.sidebar.image("logo.png", width=160)
st.sidebar.markdown("**Automatizaci√≥n de Indicadores**")


TZ_MX = pytz.timezone("America/Mexico_City")

def safe_round(x, n):
    try:
        return round(float(x), n)
    except Exception:
        return None

def sie_opportuno(series_ids, banxico_token: str):
    if isinstance(series_ids, (list, tuple)):
        sid = ",".join(series_ids)
    else:
        sid = series_ids
    url = f"https://www.banxico.org.mx/SieAPIRest/service/v1/series/{sid}/datos/oportuno"
    headers = {"Bmx-Token": banxico_token.strip()}
    r = requests.get(url, headers=headers, timeout=30)
    r.raise_for_status()
    data = r.json().get("bmx", {}).get("series", [])
    out = {}
    for s in data:
        try:
            out[s["idSerie"]] = float(str(s["datos"][0]["dato"]).replace(",", ""))
        except Exception:
            out[s["idSerie"]] = None
    return out

def fetch_tiie_from_dof():
    try:
        url = "https://sidof.segob.gob.mx/historicoIndicadores"
        r = requests.get(url, timeout=30); r.raise_for_status()
        text = " ".join(BeautifulSoup(r.text, "lxml").stripped_strings)

        def grab(patterns):
            for pat in patterns:
                m = re.search(pat, text, flags=re.I)
                if m:
                    try:
                        return float(m.group(1).replace(",", ""))
                    except Exception:
                        pass
            return None

        return {
            "tiie_28":  safe_round(grab([r"TIIE\s*28\s*D[I√ç]AS\s*([0-9]+(?:\.[0-9]+)?)\s*%", r"TIIE\s*28\s*D[I√ç]AS\s*([0-9]+(?:\.[0-9]+)?)"]), 4),
            "tiie_91":  safe_round(grab([r"TIIE\s*91\s*D[I√ç]AS\s*([0-9]+(?:\.[0-9]+)?)\s*%", r"TIIE\s*91\s*D[I√ç]AS\s*([0-9]+(?:\.[0-9]+)?)"]), 4),
            "tiie_182": safe_round(grab([r"TIIE\s*182\s*D[I√ç]AS\s*([0-9]+(?:\.[0-9]+)?)\s*%", r"TIIE\s*182\s*D[I√ç]AS\s*([0-9]+(?:\.[0-9]+)?)"]), 4),
        }
    except Exception:
        return {"tiie_28": None, "tiie_91": None, "tiie_182": None}

def cetes_sie(banxico_token: str):
    ids = ["SF43936", "SF43939", "SF43942", "SF43945"]  # 28, 91, 182, 364
    mp  = {"SF43936":"28","SF43939":"91","SF43942":"182","SF43945":"364"}
    out = {"28":None,"91":None,"182":None,"364":None}
    try:
        data = sie_opportuno(ids, banxico_token)
        for k, v in data.items():
            if mp.get(k) and v is not None:
                out[mp[k]] = safe_round(v, 4)
    except Exception:
        pass
    return out

def monex_compra_venta(usd_fix=None):
    try:
        r = requests.get("https://www.monex.com.mx/", timeout=25)
        if r.status_code == 200:
            txt = " ".join(BeautifulSoup(r.text, "lxml").stripped_strings)
            m = re.search(r"(?:D[o√≥]lar|USD)[^0-9]*(?:Compra|compra)\s*([0-9]+\.[0-9]{2,4})[^0-9]*(?:Venta|venta)\s*([0-9]+\.[0-9]{2,4})", txt)
            if m:
                compra = float(m.group(1)); venta = float(m.group(2))
                if 10 <= compra <= 30 and 10 <= venta <= 30:
                    return round(compra,4), round(venta,4)
    except Exception:
        pass
    if usd_fix:
        sp = usd_fix * 0.0025  # +/-0.25%
        return round(usd_fix - sp, 4), round(usd_fix + sp, 4)
    return None, None

def fetch_uma_values():
    def parse_table(url):
        try:
            r = requests.get(url, timeout=30); r.raise_for_status()
            soup = BeautifulSoup(r.text, "lxml")
            table = soup.find("table")
            if not table: return None
            best_year, vals = -1, None
            for tr in table.find_all("tr"):
                cols = [c.get_text(strip=True) for c in tr.find_all(["td","th"])]
                if len(cols) < 4: continue
                my = re.search(r"\b(20\d{2})\b", cols[0])
                if not my: continue
                year = int(my.group(1))
                def to_f(s): return float(s.replace("$","").replace(",","").replace("\xa0",""))
                try:
                    d = to_f(cols[1]); m = to_f(cols[2]); a = to_f(cols[3])
                    if year > best_year and d > 0:
                        best_year, vals = year, (d, m, a)
                except Exception:
                    continue
            return vals
        except Exception:
            return None

    def parse_regex(url):
        try:
            r = requests.get(url, timeout=30); r.raise_for_status()
            text = " ".join(BeautifulSoup(r.text, "lxml").stripped_strings)
            m = re.search(r"(20\d{2}).*?\$?\s*([0-9]+(?:[.,][0-9]+)?)\s*\$?\s*([0-9][0-9.,]*)\s*\$?\s*([0-9][0-9.,]*)", text)
            if m:
                def to_f(s): return float(s.replace("$","").replace(",",""))
                return to_f(m.group(2)), to_f(m.group(3)), to_f(m.group(4))
            return None
        except Exception:
            return None

    for url in ("https://www.inegi.org.mx/temas/uma/", "https://en.www.inegi.org.mx/temas/uma/"):
        vals = parse_table(url)
        if vals: return vals
    for url in ("https://www.inegi.org.mx/temas/uma/", "https://en.www.inegi.org.mx/temas/uma/"):
        vals = parse_regex(url)
        if vals: return vals

    return (113.14, 3439.46, 41273.52)

def build_news_bullets(max_items=10):
    bullets = []
    query = (
        "peso mexicano volatilidad OR Banxico OR TIIE OR CETES OR inflaci√≥n "
        "OR Pemex OR SHCP OR deuda soberana OR huracanes M√©xico OR geopol√≠tica M√©xico "
        "OR presupuesto federal 2026 OR nearshoring"
    )
    rss_url = "https://news.google.com/rss/search?q=" + quote_plus(query) + "&hl=es-419&gl=MX&ceid=MX:es-419"
    try:
        d = feedparser.parse(rss_url)
        for e in d.entries[:max_items]:
            title = (e.title or "").strip()
            link  = (e.link or "").strip()
            if title and link:
                bullets.append(f"‚Ä¢ {title} ‚Äî {link}")
    except Exception:
        pass

    if bullets:
        return "\n".join(bullets)

    feeds = [
        "https://www.reuters.com/markets/americas/mexico/feed/?rpc=401&",
        "https://www.reuters.com/world/americas/mexico/feed/?rpc=401&",
        "https://www.banxico.org.mx/rss/prensa.xml",
        "https://www.eleconomista.com.mx/rss/economia",
        "https://www.elfinanciero.com.mx/rss/finanzas/",
    ]
    keywords = [
        "M√©xico","Banxico","inflaci√≥n","tasa","TIIE","CETES","d√≥lar","tipo de cambio",
        "volatilidad","Fed","FOMC","Pemex","rating","Fitch","Moody","S&P",
        "d√©ficit","fiscal","hurac√°n","geopol√≠tica","presupuesto","nearshoring"
    ]
    rows = []
    for url in feeds:
        try:
            fp = feedparser.parse(url)
            for e in fp.entries[:40]:
                title = (e.get("title","") or "").strip()
                summary = (e.get("summary","") or "")
                link = (e.get("link","") or "").strip()
                txt = f"{title} {summary}".lower()
                if any(k.lower() in txt for k in keywords):
                    rows.append((e.get("published",""), title, link))
        except Exception:
            pass
    try:
        rows.sort(reverse=True, key=lambda x: x[0])
    except Exception:
        pass
    for _, title, link in rows[:max_items]:
        bullets.append(f"‚Ä¢ {title} ‚Äî {link}")
    return "\n".join(bullets) if bullets else "Sin novedades (verifica conexi√≥n y RSS)."

st.title("üìä Automatizaci√≥n de Indicadores de Maricela")
st.write("Sube tu archivo Excel y generar√© el actualizado listo para descargar.")

uploaded = st.file_uploader("Selecciona tu archivo .xlsx", type=["xlsx"])
run_news = st.checkbox("Indicadores_actualizado", value=True)
do_process = st.button("Procesar y generar archivo")

if do_process:
    if uploaded is None:
        st.error("Primero selecciona un archivo .xlsx.")
        st.stop()

    raw = uploaded.getvalue()
    bio_in = io.BytesIO(raw)
    try:
        wb = load_workbook(bio_in, data_only=True)
    except Exception as e:
        st.error(f"No pude abrir el Excel: {e}")
        st.stop()

    for hoja in ("Token","Indicadores","Noticias"):
        if hoja not in wb.sheetnames:
            st.error(f'No encuentro la hoja "{hoja}".')
            st.stop()

    ws_tok = wb["Token"]; ws_ind = wb["Indicadores"]; ws_new = wb["Noticias"]

    BANXICO_TOKEN = str(ws_tok["A2"].value or "").strip()
    INEGI_TOKEN   = str(ws_tok["C2"].value or "").strip()
    if not BANXICO_TOKEN:
        st.error("Falta BANXICO_TOKEN en Token!A2.")
        st.stop()

    FECHA_HOY = datetime.now(TZ_MX).strftime("%d/%m/%Y")

    try:
        fx = sie_opportuno(["SF43718","SF46406","SF46410"], BANXICO_TOKEN)
    except Exception as e:
        st.error(f"Error consultando SIE (FX): {e}")
        st.stop()

    usd_mxn = fx.get("SF43718")
    jpy_mxn = fx.get("SF46406")
    eur_mxn = fx.get("SF46410")
    usd_jpy = (usd_mxn / jpy_mxn) if (usd_mxn and jpy_mxn) else None
    eur_usd = (eur_mxn / usd_mxn) if (eur_mxn and usd_mxn) else None

    monex_compra, monex_venta = monex_compra_venta(usd_fix=usd_mxn)

    tasa_obj = sie_opportuno(["SF61745"], BANXICO_TOKEN).get("SF61745")
    tiie = fetch_tiie_from_dof()

    cetes = cetes_sie(BANXICO_TOKEN)

    udis = sie_opportuno(["SP68257"], BANXICO_TOKEN).get("SP68257")

    uma_diaria, uma_mensual, uma_anual = fetch_uma_values()

    if run_news:
        ws_new["A2"] = build_news_bullets(max_items=12)

    ws_ind["F7"]  = FECHA_HOY
    ws_ind["F10"] = safe_round(usd_mxn, 4)

    ws_ind["F12"] = safe_round(monex_compra, 4)
    ws_ind["F13"] = safe_round(monex_venta, 4)

    ws_ind["F16"] = safe_round(jpy_mxn, 6)
    ws_ind["F17"] = safe_round(usd_jpy, 6)

    ws_ind["F21"] = safe_round(eur_mxn, 6)
    ws_ind["F22"] = safe_round(eur_usd, 6)

    ws_ind["L7"]  = FECHA_HOY
    ws_ind["L8"]  = safe_round(tasa_obj, 4)
    ws_ind["L9"]  = safe_round(tiie.get("tiie_28"), 4)
    ws_ind["L10"] = safe_round(tiie.get("tiie_91"), 4)
    ws_ind["L11"] = safe_round(tiie.get("tiie_182"), 4)

    ws_ind["L14"] = FECHA_HOY
    ws_ind["L15"] = safe_round(cetes.get("28"), 4)
    ws_ind["L16"] = safe_round(cetes.get("91"), 4)
    ws_ind["L17"] = safe_round(cetes.get("182"), 4)
    ws_ind["L18"] = safe_round(cetes.get("364"), 4)

    ws_ind["F32"] = FECHA_HOY
    ws_ind["F33"] = safe_round(udis, 6)

    ws_ind["K32"] = FECHA_HOY
    ws_ind["K33"] = safe_round(uma_diaria, 2)
    ws_ind["K34"] = safe_round(uma_mensual, 2)
    ws_ind["K35"] = safe_round(uma_anual, 2)

    out = io.BytesIO()
    wb.save(out)
    out.seek(0)

    st.success("¬°Listo! Archivo actualizado.")
    st.download_button(
        label="‚¨áÔ∏è Descargar Excel actualizado",
        data=out,
        file_name=os.path.splitext(uploaded.name)[0] + "_actualizado.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )

    st.subheader("Resumen")
    df_res = pd.DataFrame({
        "Campo": [
            "USD/MXN FIX (F10)", "Monex compra (F12)", "Monex venta (F13)",
            "JPY->MXN (F16)", "USD->JPY (F17)",
            "EUR->MXN (F21)", "EUR->USD (F22)",
            "Tasa objetivo (L8)", "TIIE 28 (L9)", "TIIE 91 (L10)", "TIIE 182 (L11)",
            "CETES 28/91/182/364 (L15..L18)",
            "UDIS (F33)",
            "UMA D/M/A (K33..K35)",
        ],
        "Valor": [
            usd_mxn, monex_compra, monex_venta,
            jpy_mxn, (usd_mxn / jpy_mxn) if (usd_mxn and jpy_mxn) else None,
            eur_mxn, (eur_mxn / usd_mxn) if (eur_mxn and usd_mxn) else None,
            tasa_obj, tiie.get("tiie_28"), tiie.get("tiie_91"), tiie.get("tiie_182"),
            f"{cetes.get('28')} / {cetes.get('91')} / {cetes.get('182')} / {cetes.get('364')}",
            udis,
            f"{uma_diaria} / {uma_mensual} / {uma_anual}",
        ]
    })
    st.dataframe(df_res, use_container_width=True)
